% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/metrics.R
\name{pacc_vec}
\alias{pacc_vec}
\title{Positive Accuracy metric}
\usage{
pacc_vec(
  truth,
  estimate,
  estimator = NULL,
  na_rm = TRUE,
  case_weights = NULL,
  event_level = "first",
  ...
)
}
\arguments{
\item{truth}{truth value (0 or 1)}

\item{estimate}{estimates (note that they're limited to 0..1 and are rounded in the function to either 0 or 1)}

\item{na_rm}{whether to remove NA cases - not used}

\item{case_weights}{ignored, required for yardstick metrics}

\item{event_level}{Event level = normally th first level in truth is assumed to be the event case, can change here.}

\item{...}{unused}
}
\value{
a numeric value between 0 and 1 (higher is better)
}
\description{
Subsets the normal accuracy metric to only count the target/positive position(s). For example, picking all 0 for win
chance would normally give a 95% accuracy (1 in 20 is wrong - 1 in 20 wins). This function only looks at the accuracy
relative to the truth == 1 case (i.e. correctly or not pick the winner). Works for win or for podium or points models.
}
\details{
Idea inspired by https://towardsdatascience.com/formula-1-race-predictor-5d4bfae887da
}
\seealso{
[pacc()] for data.frame version
}
